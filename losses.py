
import config
import torch
import torch.nn as nn

'''
Losses would only be used while training.
Funcs and classes: 
	(1). class KDLoss(nn.Module): Loss Function for Knowledge Distillation.
	(2). class SSLLoss(nn.Module): 	Semi supervised loss function. 
		 In fact, it is the same as BCE loss, however the pesudo label is soft and generated by the distillition.
	(3). class SSLLoss_raw(nn.Module): Semi-supervised loss function. BCE_soft(T == 1) + BCE_hard.
	(4). class KD_SSLLoss(nn.Module): a combination of KDLoss and SSLLoss, with two mode provided.
'''
class KDLoss(nn.Module):
	'''
	Loss Function for Knowledge Distillation.
	Functions:
		(1). __init__(self): initilization for different loss parts.
		(2). forward(self, output_NN, output_distiller, softLabel, hardLabel): forword propagation for the KDLoss
	Description:
		(a). KD Loss function
	'''
	def __init__(self, phase):
		'''
		initiallizer, set sub loss funtions
		Input:
			phase: 'KD'/'SSL_KD'(meaning it will also be used in SSL mode)
		Output:
			----
		'''
		super().__init__()
		self.phase = phase
		if(self.phase == 'KD'):
			self.T = config.KD_T
			self.LAMBDA_KD = config.LAMBDA_KD
		elif(self.phase == 'SSL_KD'):
			self.T = config.SSL_T
			self.LAMBDA_KD = config.LAMBDA_SSL_KD
		self.criterion_soft = nn.BCELoss()
		self.criterion_hard = nn.BCELoss()

	def forward(self, output_NN, output_T, hardLabel, softLabel):
		'''
		forward function, how the loss is calculated for Loss_KD.
		Input:
			output_NN: T == 1
			output_T: T == T, output for single model in distillation mode.
			softLabel, hardLabel: soft target got from the distiller, and the True hard label.
		Output:
		'''
		# print(output_NN.dtype, ' ', output_T.dtype, ' ', softLabel.dtype, ' ', hardLabel.dtype)
		softLabel.to(output_NN.device)
		BCELoss_soft = self.criterion_soft(output_T, softLabel)
		BCELoss_hard = self.criterion_hard(output_NN, hardLabel)
		loss = self.LAMBDA_KD *  self.T * self.T * BCELoss_soft + (1 - self.LAMBDA_KD) * BCELoss_hard
		return loss

class SSLLoss(nn.Module):
	'''
	Semi supervised loss function.
	It is nearly same as BCE loss, however the pesudo label is soft and generated by the distillition, corresponding T is multiplied.
	Functions:
		(1).  __init__(self): initilization for different loss parts.
		(2). forward(self, output_unlabel, softLabel_unlabel): .
	Description:
		(a). SSL Loss function
	'''
	def __init__(self):
		'''
		initiallizer
		'''
		super().__init__()
		self.criterion_soft_unlabel = nn.BCELoss()

	def forward(self, output_unlabel, softLabel_unlabel):
		'''
		forward function, how the loss is calculated for SSLLoss
		'''
		loss = config.SSL_T *  config.SSL_T * self.criterion_soft_unlabel(output_unlabel, softLabel_unlabel)
		return loss

class SSLLoss_raw(nn.Module):
	'''
	Semi-supervised loss function. BCE_soft(T == 1) + BCE_hard.
	Functions:
		(1).  __init__(self): initilization for different loss parts.
		(2). forward(self, output_unlabel, softLabel_unlabel): .
	Description:
		(a). SSL Loss function
	'''
	def __init__(self):
		'''
		initiallizer
		'''
		super().__init__()
		self.criterion_labeled = nn.BCELoss() # T == 1
		self.criterion_unlabeled = nn.BCELoss() # T == 1

	def forward(self, output_label, output_unlabel, groundTruthLabel_label, pesudolabel_unlabel):
		'''
		Input:
			output_label, output_unlabel: NN output for labeled and unlabeled data with T == 1.
			groundTruthLabel_label, pesudolabel_unlabel: true label for labeled data and pesudo label for unlabeled data.
		output:
			loss: ----
		'''
		loss = config.LAMBDA_SSL * self.criterion_unlabeled(output_unlabel, pesudolabel_unlabel) + \
				(1 - config.LAMBDA_SSL) * self.criterion_labeled(output_label, groundTruthLabel_label)
		return loss


class KD_SSLLoss(nn.Module):
	'''
	KD_SSLLoss: a combination of KDLoss and SSLLoss, with two mode provided.
	In the 'soft' mode, the SSLLoss part is calculated by the model output and the soft label.
	In the 'multi' mode, the SSLLoss part is calculated by the
															model output and soft label.
															moidel output and pesudo hard label. (pesudo KD)
	Functions:
		(1).  __init__(self): initilization.
		(2). forward(self, output_1, output_T, hardLabel, softLabel, output_unlabel_T, softLabel_unlabel, 
					output_unlabel_1 = None, pesudoHardLabel_unlabel = None):
	Description:
		(a). SSL Loss function
	'''
	def __init__(self, phase):
		'''
		Initialize.
		'''
		super().__init__()
		self.phase = phase # 'multi'/'soft', ways to deal with the unlabel data.
		self.criterion_KD = KDLoss('KD')
		# only in T mode
		if(self.phase == 'multi'): # too troublesome & not necessary.
			self.criterion_SSL = KDLoss('SSL_KD')
		elif(self.phase == 'soft'):
			self.criterion_SSL = SSLLoss()

	def forward(self, output_1, output_T, hardLabel, softLabel, output_unlabel_T, softLabel_unlabel, output_unlabel_1 = None, pesudoHardLabel_unlabel = None):
		'''
		output_unlabel_1: not welled named.
		Input:
			output_1, output_T: output for labeled data with T in [1, T].
			hardLabel, softLabel: hard label and soft label (ditiller generated) for labeled data.
			output_unlabel_T, softLabel_unlabel: output for unlabeled data under T and coresponding soft label generated by the ditiller.
			output_unlabel_1, pesudoHardLabel_unlabel: output for unlabeled data under T and the pesudo hard label. (only useful in multi mode)
		Output:
			loss: ----
		Description:
			'soft':	lambda_unlabel * BCE_soft(SSL_T) + (1 - lambda_unlabel) * KDLoss(KD_T, LAMBDA_KD)
			'multi': lambda_unlabel * KDLoss(SSL_T, LAMBDA_SSL_KD) + (1 - lambda_unlabel) * KDLoss(KD_T, LAMBDA_KD)
		'''
		loss_KD = self.criterion_KD(output_1, output_T, hardLabel, softLabel)
		if(self.phase == 'multi'): # KD + KD
			loss_SSL = self.criterion_SSL(output_unlabel_1, output_unlabel_T, pesudoHardLabel_unlabel, softLabel_unlabel)
		elif(self.phase == 'soft'): # BCE + KD
			# lambda_unlabel * BCE_soft + (1 - lambda_unlabel) * KDLoss
			loss_SSL = self.criterion_SSL(output_unlabel_T, softLabel_unlabel)
		# print('loss_KD:{}, loss_SSL:{}\n'.format(loss_KD.item(), loss_SSL.item()))
		loss = config.LAMBDA_UNLABEL * loss_SSL + (1 - config.LAMBDA_UNLABEL) * loss_KD
		return loss


if __name__ == '__main__':
	pass